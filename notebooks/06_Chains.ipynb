{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "711755c9",
   "metadata": {},
   "source": [
    "# Chains\n",
    "\n",
    "- Sequência de operações ou chamadas de API que são executadas de maneira encadeada para completar uma tarefa complexa.\n",
    "- **Automatização de Processos**: Facilita a automação de fluxos de trabalho complexos.\n",
    "- **Eficiência**: Reduz a nescessidade de intervenção manual, permitindo que as tarefas sejam executadas de forma contínua e eficiente.\n",
    "- **Flexibilidade**: Permite combinar diferentes operações e modelos para criar soluções personalizadas.\n",
    "\n",
    "# Exemplos \n",
    "- **Simples**\n",
    "- **Sequential Chain**\n",
    "- **Router Chain**\n",
    "\n",
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "197ca5e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import OpenAI\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3254c13e",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai = OpenAI(model_name='gpt-3.5-turbo-instruct', temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a9a4fb6",
   "metadata": {},
   "source": [
    "# Simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5261400d",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = PromptTemplate.from_template('Descreva as tendências tecnológicas em {ano}.')\n",
    "runnable_sequence = prompt_template | openai\n",
    "output = runnable_sequence.invoke({'ano':'2026'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "477b2a4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output:\n",
      " \n",
      "\n",
      "1. Inteligência Artificial (IA): A IA continuará a ser uma das principais tendências tecnológicas em 2026, com avanços significativos em áreas como aprendizado de máquina, processamento de linguagem natural e robótica. A IA será cada vez mais integrada em nossas vidas, desde assistentes virtuais até carros autônomos.\n",
      "\n",
      "2. Internet das Coisas (IoT): A IoT também continuará a crescer e se expandir em 2026, com mais dispositivos conectados e uma maior integração com a IA. Isso permitirá que as pessoas controlem e monitorem suas casas, carros e outros dispositivos de forma mais eficiente e conveniente.\n",
      "\n",
      "3. Realidade Virtual (VR) e Realidade Aumentada (AR): A VR e a AR estão se tornando cada vez mais populares e acessíveis, e em 2026, elas serão amplamente utilizadas em vários setores, como jogos, educação, saúde e treinamento.\n",
      "\n",
      "4. Blockchain: A tecnologia blockchain, que é a base das criptomoedas, continuará a evoluir e ser adotada\n"
     ]
    }
   ],
   "source": [
    "print('Output:\\n', output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d554b3f7",
   "metadata": {},
   "source": [
    "# Sequential Chain\n",
    "\n",
    "- 'n' etapas(elos da chain) executadas em sequência\n",
    "- A saída de uma etapa pode ser transformada\n",
    "- Podemos definir quais são as entradas de uma etapa\n",
    "\n",
    "![image.png](imgs/sequentialchain.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb728f2",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fcc6cea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "\n",
    "openai = ChatOpenAI(model_name='gpt-4o', temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "919e6459",
   "metadata": {},
   "source": [
    "# Sequential Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cadc4b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar documentos\n",
    "loader = TextLoader('documents/base_conhecimento_britadeira.txt')\n",
    "documents = loader.load()\n",
    "\n",
    "# Carregar histórico de conversas\n",
    "historico_conversas = '''Cliente: Minha britadeira não liga.\n",
    "Chatbot: Você já verificou se a bateria está carregada e conectada corretamente?'''\n",
    "\n",
    "# Pergunta do cliente\n",
    "pergunta = 'Minha britadeira não liga. Eu já verifiquei e a bateria está carregada e conectada corretamente.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f5eb9404",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = {\n",
    "    'context':'\\n'.join(doc.page_content for doc in documents),\n",
    "    'question': pergunta,\n",
    "    'historico': historico_conversas\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "521a580f",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_base_conhecimento = PromptTemplate(\n",
    "    input_variables=['context', 'question'],\n",
    "    template='''Use o seguinte contexto para responder à pergunta.\n",
    "    Responda apenas com base nas informações fornecidas. \n",
    "    Não forneça instruções de procedimentos já realizados.\n",
    "    Não utilize informações externas ao contexto:\n",
    "    Contexto: {contexto}\n",
    "    Pergunta: {question}'''\n",
    ")\n",
    "\n",
    "prompt_historico_conversas = PromptTemplate(\n",
    "    input_variables=['historico','question'],\n",
    "    template='''Use o histórico de conversas para responder à pergunta.\n",
    "    Responda apenas com base nas informações fornecidas.\n",
    "    Não forneça instruções de procedimentos já realizados.\n",
    "    Não utilize informações externas ao contexto:\n",
    "    Histórico: {historico}\n",
    "    Pergunta: {question}'''\n",
    ")   \n",
    "\n",
    "prompt_final = PromptTemplate(\n",
    "    input_variables=['reposta_base_conhecimento','resposta_historico_conversas'],\n",
    "    template='''Combine as seguintes respostas para gerar uma resposta final, \n",
    "    mas não forneça intruções de procedimentos já realizados:\n",
    "    Resposta da base de conhecimento: {resposta_base_conhecimento}\n",
    "    Resposta do histórico de conversas: {resposta_historico_conversas}'''\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6ba712ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['contexto', 'question'] input_types={} partial_variables={} template='Use o seguinte contexto para responder à pergunta.\\n    Responda apenas com base nas informações fornecidas. \\n    Não forneça instruções de procedimentos já realizados.\\n    Não utilize informações externas ao contexto:\\n    Contexto: {contexto}\\n    Pergunta: {question}'\n"
     ]
    }
   ],
   "source": [
    "print(prompt_base_conhecimento)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f5cc7027",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir cadeias\n",
    "chain_base_conhecimento = prompt_base_conhecimento | openai\n",
    "chain_historico_conversas = prompt_historico_conversas | openai\n",
    "chain_final = prompt_final | openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "062053a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first=PromptTemplate(input_variables=['contexto', 'question'], input_types={}, partial_variables={}, template='Use o seguinte contexto para responder à pergunta.\\n    Responda apenas com base nas informações fornecidas. \\n    Não forneça instruções de procedimentos já realizados.\\n    Não utilize informações externas ao contexto:\\n    Contexto: {contexto}\\n    Pergunta: {question}') middle=[] last=ChatOpenAI(profile={'max_input_tokens': 128000, 'max_output_tokens': 16384, 'image_inputs': True, 'audio_inputs': False, 'video_inputs': False, 'image_outputs': False, 'audio_outputs': False, 'video_outputs': False, 'reasoning_output': False, 'tool_calling': True, 'structured_output': True, 'image_url_inputs': True, 'pdf_inputs': True, 'pdf_tool_message': True, 'image_tool_message': True, 'tool_choice': True}, client=<openai.resources.chat.completions.completions.Completions object at 0x000001C665707C50>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x000001C665958050>, root_client=<openai.OpenAI object at 0x000001C6657079D0>, root_async_client=<openai.AsyncOpenAI object at 0x000001C665707D90>, model_name='gpt-4o', temperature=0.0, model_kwargs={}, openai_api_key=SecretStr('**********'), stream_usage=True)\n"
     ]
    }
   ],
   "source": [
    "print(chain_base_conhecimento)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0ccfab5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first=PromptTemplate(input_variables=['historico', 'question'], input_types={}, partial_variables={}, template='Use o histórico de conversas para responder à pergunta.\\n    Responda apenas com base nas informações fornecidas.\\n    Não forneça instruções de procedimentos já realizados.\\n    Não utilize informações externas ao contexto:\\n    Histórico: {historico}\\n    Pergunta: {question}') middle=[] last=ChatOpenAI(profile={'max_input_tokens': 128000, 'max_output_tokens': 16384, 'image_inputs': True, 'audio_inputs': False, 'video_inputs': False, 'image_outputs': False, 'audio_outputs': False, 'video_outputs': False, 'reasoning_output': False, 'tool_calling': True, 'structured_output': True, 'image_url_inputs': True, 'pdf_inputs': True, 'pdf_tool_message': True, 'image_tool_message': True, 'tool_choice': True}, client=<openai.resources.chat.completions.completions.Completions object at 0x000001C665707C50>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x000001C665958050>, root_client=<openai.OpenAI object at 0x000001C6657079D0>, root_async_client=<openai.AsyncOpenAI object at 0x000001C665707D90>, model_name='gpt-4o', temperature=0.0, model_kwargs={}, openai_api_key=SecretStr('**********'), stream_usage=True)\n"
     ]
    }
   ],
   "source": [
    "print(chain_historico_conversas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7f4c39b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Passando dados e executando\n",
    "resultado_base_conhecimento = chain_base_conhecimento.invoke({\n",
    "    'contexto':inputs['context'], 'question':inputs['question']\n",
    "})\n",
    "resultado_historico_conversas = chain_historico_conversas.invoke({\n",
    "    'historico':inputs['historico'], 'question':inputs['question']\n",
    "})\n",
    "resultado_final = chain_final.invoke({\n",
    "    'resposta_base_conhecimento': resultado_base_conhecimento,\n",
    "    'resposta_historico_conversas': resultado_historico_conversas\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "577369c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultado Base de Conhecimento:\n",
      " content='Aguarde 30 segundos após conectar a bateria para que o sistema inicialize. Verifique se o interruptor liga/desliga está na posição correta. Se o problema persistir, contate o suporte técnico pelo 0800 555 5555.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 52, 'prompt_tokens': 871, 'total_tokens': 923, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_64dfa806c7', 'id': 'chatcmpl-DAcp8Jh47CoT69LEL0awBoDHS88Um', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='lc_run--019c7126-b5bd-7df3-a3fc-acea46a0b022-0' tool_calls=[] invalid_tool_calls=[] usage_metadata={'input_tokens': 871, 'output_tokens': 52, 'total_tokens': 923, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n",
      "---------------------------------------------------------\n",
      "Resultado Histórico de Conversas:\n",
      " content='Você já verificou se há algum problema com o interruptor de ligar/desligar ou se há algum fio solto?' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 25, 'prompt_tokens': 104, 'total_tokens': 129, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_64dfa806c7', 'id': 'chatcmpl-DAcpAtqY0h6dDHiKggNKvEy4v7Tqf', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='lc_run--019c7126-bedd-71d2-9095-0cea6b417b24-0' tool_calls=[] invalid_tool_calls=[] usage_metadata={'input_tokens': 104, 'output_tokens': 25, 'total_tokens': 129, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "print('Resultado Base de Conhecimento:\\n', resultado_base_conhecimento)\n",
    "print('---------------------------------------------------------')\n",
    "print('Resultado Histórico de Conversas:\\n', resultado_historico_conversas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "32d2cda3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aguarde 30 segundos após conectar a bateria para que o sistema inicialize. Verifique se o interruptor liga/desliga está na posição correta e se há algum fio solto. Se o problema persistir, contate o suporte técnico pelo 0800 555 5555.\n"
     ]
    }
   ],
   "source": [
    "print(resultado_final.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "48214365",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Aguarde 30 segundos após conectar a bateria para que o sistema inicialize. Verifique se o interruptor liga/desliga está na posição correta e se há algum fio solto. Se o problema persistir, contate o suporte técnico pelo 0800 555 5555.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 59, 'prompt_tokens': 681, 'total_tokens': 740, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_18e61aa3bc', 'id': 'chatcmpl-DAcpCBJqe5ByCDUHu7tz7ajYjhqfE', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='lc_run--019c7126-c577-7163-ba23-576e42a92a80-0' tool_calls=[] invalid_tool_calls=[] usage_metadata={'input_tokens': 681, 'output_tokens': 59, 'total_tokens': 740, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "print(resultado_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "676de9f4",
   "metadata": {},
   "source": [
    "# Router Chain\n",
    "- Um \"roteador\" decide, com base na entrada do usuário, qual deve ser a etapa seguinte\n",
    "- Cada etapa pode ter diferentes templates, modelos, e seguirem fluxos diferentes\n",
    "\n",
    "![routerchain.png](imgs/routerchain.png)\n",
    "\n",
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f2acd73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "openai = OpenAI(model_name='gpt-3.5-turbo-instruct',temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e628a4",
   "metadata": {},
   "source": [
    "# RouterChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "10ad6578",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = (\n",
    "    PromptTemplate.from_template(\n",
    "        '''\n",
    "        Classifique a pergunta do usuário em uma das seguintes categorias:\n",
    "        - Assuntos Financeiros\n",
    "        - Suporte Técnico\n",
    "        - Atualização de Cadastro\n",
    "        - Outras Informações\n",
    "\n",
    "        Pergunta: {query}\n",
    "        Classificação:\n",
    "        '''\n",
    "    )\n",
    "    | openai\n",
    "    | StrOutputParser()\n",
    ")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f21ed5ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first=PromptTemplate(input_variables=['query'], input_types={}, partial_variables={}, template='\\n        Classifique a pergunta do usuário em uma das seguintes categorias:\\n        - Assuntos Financeiros\\n        - Suporte Técnico\\n        - Atualização de Cadastro\\n        - Outras Informações\\n\\n        Pergunta: {query}\\n        Classificação:\\n        ') middle=[OpenAI(client=<openai.resources.completions.Completions object at 0x000001C6685339D0>, async_client=<openai.resources.completions.AsyncCompletions object at 0x000001C668654190>, temperature=0.0, model_kwargs={}, openai_api_key=SecretStr('**********'))] last=StrOutputParser()\n"
     ]
    }
   ],
   "source": [
    "print(chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e55b3820",
   "metadata": {},
   "outputs": [],
   "source": [
    " # elos específicos\n",
    "financial_chain = PromptTemplate.from_template(\n",
    "    '''\n",
    "    Você é um especialista financeiro.\n",
    "    Sempre responda às perguntas começando com \"Bem-vindo ao Suporte Financeiro.\n",
    "    Responda à pergunta do usuário:\n",
    "    Pergunta : {query}\n",
    "    Resposta:\n",
    "    '''\n",
    ") | openai\n",
    "\n",
    "tech_support_chain = PromptTemplate.from_template(\n",
    "    '''\n",
    "    Você é um especialista em suporte técnico.\n",
    "    Sempre responda às perguntas começando com \"Bem-vindo ao Suporte Técnico.\n",
    "    Ajude o usuário com seu problema técnico.\n",
    "    Pergunta : {query}\n",
    "    Resposta:\n",
    "    '''\n",
    ") | openai\n",
    "\n",
    "update_registration_chain = PromptTemplate.from_template(\n",
    "    '''\n",
    "    Você é um representante de atendimento ao cliente.\n",
    "    Sempre responda às perguntas começando com \"Bem-vindo ao Suporte de Cadastro.\n",
    "    Guie o usuário na atualização de suas informações de cadastro.\n",
    "    Pergunta : {query}\n",
    "    Resposta:\n",
    "    '''\n",
    ") | openai\n",
    "\n",
    "other_into_chain = PromptTemplate.from_template(\n",
    "    '''\n",
    "    Você é um assistente de informações gerais.\n",
    "    Sempre responda às perguntas começando com \"Bem-vindo ao Suporte Financeiro.\n",
    "    Responda à pergunta do usuário:\n",
    "    Pergunta : {query}\n",
    "    Resposta:\n",
    "    '''\n",
    ") | openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "57c01767",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função de Roteamento\n",
    "def route(info):\n",
    "    topic = info['topic'].lower()\n",
    "    if 'financeiro' in topic:\n",
    "        return financial_chain\n",
    "    elif 'técnico' in topic:\n",
    "        return tech_support_chain\n",
    "    elif 'atualização' in topic or 'cadastro' in topic:\n",
    "        return update_registration_chain\n",
    "    else:\n",
    "        return other_into_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "645f8a72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Suporte Técnico\n"
     ]
    }
   ],
   "source": [
    "# Exemplos 1 suporte técnico\n",
    "classification = chain.invoke({'query':'Como faço para redefinir minha senha?'})\n",
    "print(classification) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3123459a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first=PromptTemplate(input_variables=['query'], input_types={}, partial_variables={}, template='\\n    Você é um especialista em suporte técnico.\\n    Sempre responda às perguntas começando com \"Bem-vindo ao Suporte Técnico.\\n    Ajude o usuário com seu problema técnico.\\n    Pergunta : {query}\\n    Resposta:\\n    ') middle=[] last=OpenAI(client=<openai.resources.completions.Completions object at 0x000001C6685339D0>, async_client=<openai.resources.completions.AsyncCompletions object at 0x000001C668654190>, temperature=0.0, model_kwargs={}, openai_api_key=SecretStr('**********'))\n"
     ]
    }
   ],
   "source": [
    "# chama a função route passando o topico\n",
    "response_chain = route({'topic': classification})\n",
    "print(response_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3179267d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bem-vindo ao Suporte Técnico. Para redefinir sua senha, você precisará acessar a página de login e clicar em \"Esqueceu sua senha?\". Em seguida, siga as instruções na tela para redefinir sua senha. Se você tiver problemas durante o processo, não hesite em nos contatar para obter ajuda adicional.\n"
     ]
    }
   ],
   "source": [
    "# execute o objeto correto\n",
    "response = response_chain.invoke({'query':'Como faço para redefinir minha senha?'})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "424a954c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bem-vindo ao Suporte Financeiro. Como posso ajudá-lo com o pagamento de uma fatura atrasada?\n"
     ]
    }
   ],
   "source": [
    "# Exemplo 2 (Assuntos Financeiros)\n",
    "classification = chain.invoke({'query':'Como posso pagar uma fatura atrasada?'})\n",
    "response_chain = route({'topic':classification})\n",
    "response = response_chain.invoke({'query':'Como posso pagar uma fatura atrasada?'})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6f456b0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bem-vindo ao Suporte de Cadastro. Para alterar seu endereço de e-mail, siga os seguintes passos:\n",
      "    1. Faça login na sua conta.\n",
      "    2. Clique no seu perfil no canto superior direito da página.\n",
      "    3. Selecione a opção \"Configurações\".\n",
      "    4. Na seção \"Informações de contato\", clique em \"Editar\".\n",
      "    5. Insira seu novo endereço de e-mail e clique em \"Salvar alterações\".\n",
      "    Pronto! Seu endereço de e-mail foi atualizado com sucesso. Se tiver mais alguma dúvida, não hesite em nos contatar novamente. Obrigado por escolher nossos serviços.\n"
     ]
    }
   ],
   "source": [
    "# Exemplo 3 (Atualização de Cadastro)\n",
    "classification = chain.invoke({'query':'Preciso alterar meu endereço de e-mail.'})\n",
    "response_chain = route({'topic':classification})\n",
    "response = response_chain.invoke({'query':'Preciso alterar meu endereço de e-mail.'})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6173bc7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bem-vindo ao Suporte Financeiro. A missão da empresa é fornecer soluções financeiras para nossos clientes, ajudando-os a alcançar seus objetivos e prosperar em suas vidas financeiras.\n"
     ]
    }
   ],
   "source": [
    "# Exemplo 4 (Outras Informações)\n",
    "classification = chain.invoke({'query':'Qual é a missão da empresa?'})\n",
    "response_chain = route({'topic': classification})\n",
    "response = response_chain.invoke({'query':'Qual é a missão da empresa?'})\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-learning-and-using",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
